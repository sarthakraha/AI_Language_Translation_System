{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e255c51b-8827-4a9c-9ef3-4b764740b60a",
   "metadata": {},
   "source": [
    "!pip install torch transformers sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678a217e-cb44-4636-84ab-bd04a033f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Indian Languages:\n",
      "hi - Hindi\n",
      "bn - Bengali\n",
      "ta - Tamil\n",
      "te - Telugu\n",
      "mr - Marathi\n",
      "gu - Gujarati\n",
      "pa - Punjabi\n",
      "ml - Malayalam\n",
      "kn - Kannada\n",
      "or - Odia\n",
      "as - Assamese\n",
      "ur - Urdu\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the language code (e.g., hi, bn):  hi\n",
      "Enter the Indian language text:  विविधता में एकता, भारत की सच्ची ताकत।\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translated Text (English): Unity in diversity, the real power of India.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name_mul_en = \"Helsinki-NLP/opus-mt-mul-en\"\n",
    "\n",
    "tokenizer_mul_en = MarianTokenizer.from_pretrained(model_name_mul_en)\n",
    "model_mul_en = MarianMTModel.from_pretrained(model_name_mul_en)\n",
    "\n",
    "languages = {\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"mr\": \"Marathi\",\n",
    "    \"gu\": \"Gujarati\",\n",
    "    \"pa\": \"Punjabi\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"kn\": \"Kannada\",\n",
    "    \"or\": \"Odia\",\n",
    "    \"as\": \"Assamese\",\n",
    "    \"ur\": \"Urdu\"\n",
    "}\n",
    "\n",
    "print(\"Supported Indian Languages:\")\n",
    "for code, name in languages.items():\n",
    "    print(f\"{code} - {name}\")\n",
    "\n",
    "lang_code = input(\"\\nEnter the language code (e.g., hi, bn): \").lower()\n",
    "text_to_translate = input(\"Enter the Indian language text: \")\n",
    "\n",
    "if lang_code in languages:\n",
    "    inputs = tokenizer_mul_en(text_to_translate, return_tensors=\"pt\", padding=True)\n",
    "    translated_tokens = model_mul_en.generate(**inputs)\n",
    "    output_text = tokenizer_mul_en.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    print(f\"\\nTranslated Text (English): {output_text}\")\n",
    "else:\n",
    "    print(\"\\nError: Unsupported language code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2421697-8220-433a-8543-70494461e84c",
   "metadata": {},
   "source": [
    "Indian Language to English Translation System (NLP Project)\n",
    "\n",
    "1. Problem Definition & Objective\n",
    "\n",
    "a. Selected Project Track\n",
    "\n",
    "Natural Language Processing (NLP) – Machine Translation\n",
    "\n",
    "b. Problem Statement\n",
    "\n",
    "India is a linguistically diverse country with multiple regional languages. However, English remains the dominant language for education, administration, and digital content. This creates a communication gap for users who are more comfortable using regional Indian languages. The problem addressed in this project is to build an automated system that translates text from multiple Indian languages into English accurately and efficiently.\n",
    "\n",
    "c. Real‑World Relevance & Motivation\n",
    "\n",
    "Helps non‑English speakers access English content\n",
    "Useful in education, government services, and digital platforms\n",
    "Demonstrates real‑world use of NLP and pretrained transformer models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Data Understanding & Preparation\n",
    "\n",
    "a. Dataset Source\n",
    "\n",
    "This project does not use a traditional static dataset. Instead, it uses a pretrained multilingual translation model trained on large‑scale parallel corpora.\n",
    "Model: Helsinki-NLP/opus-mt-mul-en\n",
    "Source: Hugging Face Model Hub\n",
    "Data Type: Public multilingual parallel text data\n",
    "\n",
    "\n",
    "b. Data Loading & Exploration\n",
    "\n",
    "User‑provided text acts as real‑time input data. The system accepts sentences written in supported Indian languages and processes them dynamically.\n",
    "\n",
    "Supported languages include:\n",
    "\n",
    "Hindi (hi)\n",
    "Bengali (bn)\n",
    "Tamil (ta)\n",
    "Telugu (te)\n",
    "Marathi (mr)\n",
    "Gujarati (gu)\n",
    "Punjabi (pa)\n",
    "Malayalam (ml)\n",
    "Kannada (kn)\n",
    "Odia (or)\n",
    "Assamese (as)\n",
    "Urdu (ur)\n",
    "\n",
    "\n",
    "c. Cleaning, Preprocessing & Feature Engineering\n",
    "\n",
    "Tokenization handled by MarianTokenizer\n",
    "Automatic sub‑word segmentation\n",
    "Padding and tensor conversion handled internally\n",
    "No manual feature engineering required due to transformer architecture\n",
    "\n",
    "\n",
    "d. Handling Missing Values or Noise\n",
    "\n",
    "Empty or invalid inputs are avoided through user prompts\n",
    "The pretrained model inherently handles noisy text to some extent\n",
    "\n",
    "\n",
    "3. Model / System Design\n",
    "\n",
    "a. AI Technique Used\n",
    "\n",
    "Natural Language Processing (NLP) – Transformer‑based Neural Machine Translation\n",
    "\n",
    "b. Architecture / Pipeline Explanation\n",
    "\n",
    "1. User selects language code\n",
    "\n",
    "2. User inputs text in the selected language\n",
    "\n",
    "3. Text is tokenized using MarianTokenizer\n",
    "\n",
    "4. Tokens are passed to MarianMTModel\n",
    "\n",
    "5. Model generates English translation\n",
    "\n",
    "6. Output text is decoded and displayed\n",
    "\n",
    "\n",
    "\n",
    "c. Justification of Design Choices\n",
    "\n",
    "Transformer models provide high translation accuracy\n",
    "Pretrained models reduce training cost and time\n",
    "MarianMT supports multilingual translation efficiently\n",
    "\n",
    "\n",
    "\n",
    "4. Core Implementation\n",
    "\n",
    "a. Model Inference Logic\n",
    "\n",
    "The project uses pretrained MarianMT model for inference only (no training). The model generates translated text using beam search decoding.\n",
    "\n",
    "b. Prompt Engineering\n",
    "\n",
    "Not applicable, as this project uses a pretrained translation model rather than an LLM with prompt‑based interaction.\n",
    "\n",
    "c. Prediction Pipeline\n",
    "\n",
    "Input → Tokenization → Model Generation → Decoding → Output\n",
    "\n",
    "\n",
    "d. Code Execution\n",
    "\n",
    "The notebook is designed to run top‑to‑bottom without errors when required dependencies are installed.\n",
    "\n",
    "\n",
    "\n",
    "5. Evaluation & Analysis\n",
    "\n",
    "a. Metrics Used\n",
    "\n",
    "Qualitative evaluation based on translation correctness\n",
    "Manual comparison with expected English meaning\n",
    "\n",
    "\n",
    "b. Sample Output\n",
    "\n",
    "Input (Hindi): विविधता में एकता, भारत की सच्ची ताकत।\n",
    "\n",
    "Output (English): Unity in diversity, the real power of India.\n",
    "\n",
    "c. Performance Analysis & Limitations\n",
    "\n",
    "Strengths:\n",
    "\n",
    "Accurate sentence‑level translations\n",
    "Supports multiple Indian languages\n",
    "\n",
    "\n",
    "Limitations:\n",
    "\n",
    "One‑directional translation (to English only)\n",
    "No numerical evaluation metrics like BLEU score\n",
    "Performance depends on pretrained data quality\n",
    "\n",
    "\n",
    "\n",
    "6. Ethical Considerations & Responsible AI\n",
    "\n",
    "a. Bias & Fairness\n",
    "\n",
    "Model may perform better on high‑resource languages\n",
    "Low‑resource languages may have slightly reduced accuracy\n",
    "\n",
    "\n",
    "b. Dataset Limitations\n",
    "\n",
    "Training data is external and not fully transparent\n",
    "Cultural nuances may not always be preserved\n",
    "\n",
    "\n",
    "c. Responsible Use of AI\n",
    "\n",
    "Intended for educational and assistive purposes\n",
    "Should not be used for legal or critical decision‑making\n",
    "\n",
    "\n",
    "\n",
    "7. Conclusion & Future Scope\n",
    "\n",
    "a. Summary of Results\n",
    "\n",
    "The project successfully demonstrates a working multilingual translation system using NLP transformers. It accurately translates Indian language text into English and showcases practical application of pretrained models.\n",
    "\n",
    "b. Future Improvements\n",
    "\n",
    "Add English → Indian language translation\n",
    "Support paragraph and document translation\n",
    "Integrate GUI or web application\n",
    "Add quantitative evaluation metrics\n",
    "Deploy as a web API or mobile app\n",
    "\n",
    "\n",
    "Project Type: Academic NLP Mini Project\n",
    "Tools Used: Python, Jupyter Notebook, Hugging Face Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba44ce-8ccd-436a-93fb-1e85994ff547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
